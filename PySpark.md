# PySpark Data Wrangling

PySpark is python API for Spark, It helps to interface with Resilient Distributed Datasets (RDDs) in Apache Spark.  It provides 
scalable & distributed possesing for variety of use cases including exploratory data analysis, ETL, Machine Learning  pipelines.

This sample project, brings some of illustration of well known data wrangline techniques using Google Colab 
